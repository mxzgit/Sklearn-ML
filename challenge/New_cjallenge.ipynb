{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is one of the classic machine learning problem, with a multiple datasets containing information about tennis matches, players and tournements, we try to predict the winner player in the match given the minimum information.</br>\n",
    "</br>\n",
    "In the following notebook I will work on different ML models to answer this problem, and at the end I will present the best model with the best accuracy score.</br>\n",
    "</br>\n",
    "NB : I don't have the result for the test data, my objective with this exercice is to show my technical capacities wiin ML and data analisys. During the implementation of each model I will present briefly its theory also.</br>\n",
    "<font size=\"2.8\" color=\"#FF4500\" >Hope you enjoy it</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environement set-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import xgboost as xgb\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data files\n",
    "#data_train     = pd.read_csv('train.csv',index_col=0)\n",
    "data_stats     = pd.read_csv('stats.csv',index_col=0)\n",
    "data_test      = pd.read_csv('test.csv')\n",
    "data_tour      = pd.read_csv('tour.csv')\n",
    "data_players   = pd.read_csv('players.csv')\n",
    "data_playerate = pd.read_csv('player_rates.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import test file\n",
    "data_test      = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data discovery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data train is the table containing examples to train the model, it could be modified to add new features to get better result. That what I will discover in the next line of code :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID1_G = player1 index (winner)</br>\n",
    "ID2_G = player2 index (loser)</br>\n",
    "ID_T_G = tournement index </br>\n",
    "ID_R_G = round </br>\n",
    "RESULT_G = match_result</br>\n",
    "DATE_G = match date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the table containing the most information on each match two players had "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID1 : L’identifiant du joueur qui a gagné le match</br>\n",
    "ID2 : L’identifiant du joueur qui a perdu le match</br>\n",
    "ID_T : L’identifiant du tournoi (voir tours_atp)</br>\n",
    "ID_R : L’identfiant du extit{round} dans le tournoi </br>\n",
    "FS_1 : Nombre de premiers services réussis par joueur 1</br>\n",
    "FS_OF1 : Nombre de premiers services par joueur 1</br>\n",
    "ACES_1 : Aces du joueur 1</br>\n",
    "DF_1 : Double Fautes commis par joueur 1</br>\n",
    "UE_1 : Unforced errors</br>\n",
    "W1S_1: Nombre de points gagnés sur premier service</br>\n",
    "W1SOF_1: Nombre de points joués sur premier service</br>\n",
    "W2S_1: Nombre de points gagnés sur second service</br>\n",
    "W2SOF_1: Nombre de points joués sur second service</br>\n",
    "WIS_1 : Nombre de points gagnés en tout</br>\n",
    "BP_1 : Nombre de balles de break gagnées</br>\n",
    "BPOF_1 : Nombre de balles de break obtenues</br>\n",
    "RPW_1 : Nombre de points gagnés</br>\n",
    "RPW_OF1 : Nombre de points jouées</br>\n",
    "Same features for player 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_players.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table containing information on each player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_playerate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table containing the ranking of each player per year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table containing information about each tournement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.isnull().sum()/data_train.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_players.isnull().sum()/data_players.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is shown for the table players most features are Null, and we could not use any of the technique to complete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_playerate.isnull().sum()/data_playerate.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_stats.isnull().sum()/data_stats.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns contains lot of missing values, I will drop them since I could not replace them with certain values (mean, median)</br>\n",
    "I should mention that during the next step, \"data preprocessing\", I will complete the missing values, drop certain columns and make opperations between columns having a certain correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_tour.isnull().sum()/data_tour.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first data preprocessing is to combine columns with hight correlation, without any calculations, we can understaind that for the number of winning point during the first serve is correlated to the number of first serve W1S_1 to W1SOF_1 (same for player2), so I will combine this two columns in one column reflecting the rate of winning first serve </br>\n",
    "The same idea goes for many columns : </br>\n",
    "W1S_1 and W1SOF_1</br>\n",
    "W2S_1 and W2SOF_1</br>\n",
    "FS_1 and FS_OF_1</br>\n",
    "BP_1 and BPOF_1</br>\n",
    "RPW_1 and RPW_OF1</br>\n",
    "and the same thing goes for player 2 </br>\n",
    "Then I will drop thes columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = [('W1SR_1', 'W1S_1', 'W1SOF_1'),\n",
    "          ('W2SR_1', 'W2S_1', 'W2SOF_1'),\n",
    "          ('FSR_1', 'FS_1', 'FSOF_1'),\n",
    "          ('BPR_1', 'BP_1', 'BPOF_1'),\n",
    "          ('RPWR_1', 'RPW_1', 'RPWOF_1'),\n",
    "          ('W1SR_2', 'W1S_2', 'W1SOF_2'),\n",
    "          ('W2SR_2', 'W2S_2', 'W2SOF_2'),\n",
    "          ('FSR_2', 'FS_2', 'FSOF_2'),\n",
    "          ('BPR_2', 'BP_2', 'BPOF_2'),\n",
    "          ('RPWR_2', 'RPW_2', 'RPWOF_2'),\n",
    "]\n",
    "for tup in tuples:\n",
    "    data_stats[tup[0]] = data_stats[tup[1]] / data_stats[tup[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats.drop(['W1S_1', 'W1SOF_1', 'W2S_1', 'W2SOF_1', 'FS_1', 'FSOF_1', 'BP_1', 'BPOF_1', 'RPW_1', 'RPWOF_1', \n",
    "                 'W1S_2', 'W1SOF_2', 'W2S_2', 'W2SOF_2', 'FS_2', 'FSOF_2', 'BP_2', 'BPOF_2', 'RPW_2', 'RPWOF_2'],\n",
    "               inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats.drop(['UE_1', 'WIS_1', 'NA_1', 'NAOF_1', 'A1S_1', 'A2S_1', 'FAST_1',\n",
    "                 'UE_2', 'WIS_2', 'NA_2', 'NAOF_2', 'A1S_2', 'A2S_2', 'FAST_2'],\n",
    "               inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_stats.isnull().sum()/data_stats.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formattage des colonnes dates\n",
    "def date_tras(df,name):\n",
    "    df[name] = pd.to_datetime(df[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_tras(data_train,'DATE_G')\n",
    "date_tras(data_stats,'MT')\n",
    "date_tras(data_playerate,'DATE_R')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of training examples: {} \\nThe number of training features: {}\".format(data_train.shape[0],data_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of distinct players : {} \\nThe number of training features: {}\".format(data_players.NAME_P.unique().shape[0],data_players.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of distinct tournement : {} \\nThe number of training features: {}\".format(data_tour.NAME_T.unique().shape[0],data_tour.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The top ten winners player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top10player = {}\n",
    "top10player_list = data_stats.ID1.value_counts().head(10)\n",
    "for player_idx in top10player_list.index:\n",
    "    top10player[data_players.NAME_P[data_players.ID_P == player_idx].iloc[0]] = top10player_list.loc[player_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.bar(range(len(top10player)), top10player.values(), align='center', color = 'green',alpha= 0.3)\n",
    "plt.xticks(range(len(top10player)), list(top10player.keys()))\n",
    "plt.title(\"The top 10 player\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix for top 10 players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats['top_ten'] = data_stats.ID1.apply(lambda x: x in top10player_list.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats_top_ten = data_stats[data_stats.top_ten == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data_stats_top_ten[['ID1','DF_1', 'TPW_1','ACES_1','W1SR_1', 'W2SR_1', 'FSR_1', 'BPR_1', 'RPWR_1','ID_R']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph there is some logical results and other that need to be reviewd, the winning rate is positively correlated to the number of Double faults is so strange, but for other metrics they are logicaly correlated :D.</br>\n",
    "We notice that the winning rate is so correlated with number of aces, which means that the player wins easely the point and the match is not so challenging.</br>\n",
    "Same thing goes for the other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 3 Favorit tournements for the 10 top players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_tournement = {}\n",
    "for player_idx in top10player_list.index:\n",
    "    player_name = data_players.NAME_P[data_players.ID_P == player_idx].iloc[0]\n",
    "    player_tournement[player_name] = data_stats.ID_T[data_stats.ID1 == player_idx].value_counts().head(3)\n",
    "    player_tournement[player_name].index = list(data_tour.NAME_T.iloc[player_tournement[player_name].index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for player in player_tournement:\n",
    "    print(\"Top 3 tournement for '{}'\".format(player))\n",
    "    print(player_tournement[player])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is so clear that this dataset is so old as these players won lot of well known tournements </br> <font color=\"red\">'NADAL' and 'Kazakhstan' so weird !!!!!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récuperer les statistique des derniers n matches entre (player1_id,player2_id)\n",
    "def last_n_match(player1_id,player2_id,n,dt_curr):\n",
    "    a = np.bitwise_and((data_stats.ID1 == player1_id).values,(data_stats.ID2 == player2_id).values)    \n",
    "    b = np.bitwise_and((data_stats.ID1 == player2_id) , (data_stats.ID2 == player1_id))\n",
    "    x = np.bitwise_or(a,b)\n",
    "    \n",
    "    # List des matches entre(player1_id,player2_id)\n",
    "    players_matches = list(data_stats[x.values].index)\n",
    "    \n",
    "    # Si on a plus que n matches, on prend les n derniers\n",
    "    if (n <= len(players_matches)):\n",
    "        matches = data_stats.loc[players_matches]\n",
    "        matches = matches.sort_values('MT',ascending=False)\n",
    "        matches = matches[matches.MT < dt_curr]\n",
    "        return matches.head(n)\n",
    "    \n",
    "    # Sinon on prend tous les matches ou retourne NONE\n",
    "    elif (0<len(players_matches) and len(players_matches)<n):\n",
    "        matches = data_stats.loc[players_matches]\n",
    "        matches = matches.sort_values('MT',ascending=False)\n",
    "        matches = matches[matches.MT <= dt_curr]\n",
    "        return matches.head(len(players_matches))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupere les résultats\n",
    "def get_info():\n",
    "    k = 0\n",
    "    for i in list(data_train.index):\n",
    "        print(\"chargement : {:.2f} %\".format(k / len(list(data_train.index)) * 100))\n",
    "        k +=1\n",
    "        \n",
    "        info_i = last_n_match(data_train.ID1_G.loc[i],data_train.ID2_G.loc[i],2,data_train.DATE_G.loc[i])\n",
    "        \n",
    "        data_train.loc[i,'PL1_1'] = 1\n",
    "        # le nombre de matche joueur 1 a gangné\n",
    "        oc1 = [0]*2\n",
    "        \n",
    "        # le nombre de matche joueur 2 a gangné\n",
    "        oc2 = [0]*2\n",
    "        \n",
    "        # Compléter la table des startistiques\n",
    "        if info_i is not None:\n",
    "            k1 = 0\n",
    "            k2 = 0\n",
    "            for j in list(info_i.ID1.index):\n",
    "                if(info_i.ID1.loc[j] == data_train.ID1_G.loc[i]):\n",
    "                    oc1[k1] = 1\n",
    "                    k1+=1\n",
    "                else:\n",
    "                    oc2[k2] = 1\n",
    "                    k2 +=1\n",
    "            \n",
    "            vec = pd.concat([pd.Series(oc1),pd.Series(oc2)],axis=0,ignore_index=True)\n",
    "            data_train.loc[i,'PL1_2'] = vec[0]\n",
    "            data_train.loc[i,'PL1_3'] = vec[1]\n",
    "            data_train.loc[i,'PL2_2'] = vec[2]\n",
    "            data_train.loc[i,'PL2_3'] = vec[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récuperer le meilleur classement du jour avant la date du matche\n",
    "def get_rate(player_id,dt_curr):   \n",
    "    player = data_playerate[data_playerate.ID_P_R == player_id]\n",
    "    if (len(player[player.DATE_R <= dt_curr]) != 0):\n",
    "        return max(player.POINT_R)\n",
    "    elif (len(player)!=0):\n",
    "        return max(player.POINT_R)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récuper les différence entre les points gangés dans les n dernier matche entre joueur1 et jouer2\n",
    "\n",
    "## W1S_j : Nombre de points gagnés sur premier service\n",
    "## W2S_j : Nombre de points gagnés sur second service\n",
    "## BP    : Nombre de balles de break gagnées\n",
    "\n",
    "def get_point():\n",
    "    k = 0\n",
    "    for i in list(data_train.index):\n",
    "        print(\"chargement : {:.2f} %\".format(k / len(data_train.ID1_G) * 100))\n",
    "        k +=1\n",
    "        info_i = last_n_match(data_train.ID1_G.loc[i],data_train.ID2_G.loc[i],3,data_train.DATE_G.loc[i])\n",
    "        \n",
    "        if info_i is not None:\n",
    "            k1 = 0\n",
    "            k2 = 0\n",
    "            for j in list(info_i.ID1.index):\n",
    "                if(info_i.ID1.loc[j] == data_train.ID1_G.loc[i]):\n",
    "                    k1 = info_i.W1SR_1.loc[j] + info_i.W2SR_1.loc[j] + info_i.BPR_1.loc[j]\n",
    "                    k2 = info_i.W1SR_2.loc[j] + info_i.W2SR_2.loc[j] + info_i.BPR_2.loc[j]\n",
    "                else:\n",
    "                    k2 = info_i.W1SR_1.loc[j] + info_i.W2SR_1.loc[j] + info_i.BPR_1.loc[j]\n",
    "                    k1 = info_i.W1SR_2.loc[j] + info_i.W2SR_2.loc[j] + info_i.BPR_2.loc[j]\n",
    "            data_train.DIFF_pts.loc[i] = k1 - k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajt(df):\n",
    "    # Resultats des 3 deriniers matches\n",
    "    df['PL1_1'] = [0]*df.ID1_G\n",
    "    df['PL1_2'] = [0]*df.ID1_G\n",
    "    df['PL1_3'] = [0]*df.ID1_G\n",
    "    df['PL2_1'] = [0]*df.ID1_G\n",
    "    df['PL2_2'] = [0]*df.ID1_G\n",
    "    df['PL2_3'] = [0]*df.ID1_G\n",
    "\n",
    "\n",
    "\n",
    "    # Difference entre les points gagnés par les deux joueurs dans les 3 derniers matches\n",
    "    df['DIFF_pts'] = [0]*df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajt(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_bck = data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv('train_data_formated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('train_data_formated.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1_G</th>\n",
       "      <th>ID2_G</th>\n",
       "      <th>ID_T_G</th>\n",
       "      <th>ID_R_G</th>\n",
       "      <th>RESULT_G</th>\n",
       "      <th>DATE_G</th>\n",
       "      <th>PL1_1</th>\n",
       "      <th>PL1_2</th>\n",
       "      <th>PL1_3</th>\n",
       "      <th>PL2_1</th>\n",
       "      <th>...</th>\n",
       "      <th>R8</th>\n",
       "      <th>R9</th>\n",
       "      <th>R10</th>\n",
       "      <th>R11</th>\n",
       "      <th>R12</th>\n",
       "      <th>R13</th>\n",
       "      <th>R14</th>\n",
       "      <th>R15</th>\n",
       "      <th>R16</th>\n",
       "      <th>R17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17613</td>\n",
       "      <td>18854</td>\n",
       "      <td>8887</td>\n",
       "      <td>4</td>\n",
       "      <td>7-6(8) 3-6 10-7</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25192</td>\n",
       "      <td>25191</td>\n",
       "      <td>8888</td>\n",
       "      <td>4</td>\n",
       "      <td>6-3 6-2</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>918</td>\n",
       "      <td>10828</td>\n",
       "      <td>8957</td>\n",
       "      <td>4</td>\n",
       "      <td>6-1 6-2</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3316</td>\n",
       "      <td>2379</td>\n",
       "      <td>8957</td>\n",
       "      <td>4</td>\n",
       "      <td>6-4 7-6(5)</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7869</td>\n",
       "      <td>6277</td>\n",
       "      <td>8957</td>\n",
       "      <td>4</td>\n",
       "      <td>6-4 6-4</td>\n",
       "      <td>2012-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID1_G  ID2_G  ID_T_G  ID_R_G         RESULT_G      DATE_G  PL1_1  PL1_2  \\\n",
       "0  17613  18854    8887       4  7-6(8) 3-6 10-7  2012-01-31      1      0   \n",
       "1  25192  25191    8888       4          6-3 6-2  2012-01-31      1      0   \n",
       "2    918  10828    8957       4          6-1 6-2  2012-01-31      1      1   \n",
       "3   3316   2379    8957       4       6-4 7-6(5)  2012-01-31      1      1   \n",
       "4   7869   6277    8957       4          6-4 6-4  2012-01-31      1      1   \n",
       "\n",
       "   PL1_3  PL2_1  ...  R8  R9  R10  R11  R12  R13  R14  R15  R16  R17  \n",
       "0      0      0  ...   0   0    0    0    0    0    0    0    0    0  \n",
       "1      0      0  ...   0   0    0    0    0    0    0    0    0    0  \n",
       "2      1      0  ...   0   0    0    0    0    0    0    0    0    0  \n",
       "3      0      0  ...   0   0    0    0    0    0    0    0    0    0  \n",
       "4      0      0  ...   0   0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['label'] = [1] * data_train.shape[0]\n",
    "from random import randint\n",
    "rn = []\n",
    "rnn = [randint(0,data_train.shape[0]-1) for i in range(int(data_train.shape[0]/3))]\n",
    "for i in rnn:\n",
    "    rn.append(data_train.index[i])\n",
    "    \n",
    "# Permutation des données\n",
    "for i in rn:\n",
    "    data_train.loc[i,'PL1_1'],data_train.loc[i,'PL2_1'] = data_train.loc[i,'PL2_1'],data_train.loc[i,'PL1_1']\n",
    "    data_train.loc[i,'PL1_2'],data_train.loc[i,'PL2_2'] = data_train.loc[i,'PL2_2'],data_train.loc[i,'PL1_2']\n",
    "    data_train.loc[i,'PL1_3'],data_train.loc[i,'PL2_2'] = data_train.loc[i,'PL2_3'],data_train.loc[i,'PL1_3']\n",
    "    \n",
    "    data_train.loc[i,'DIFF_pts'] = -1*data_train.loc[i,'DIFF_pts']     \n",
    "    \n",
    "    # joueur 2 gangant => label = 0\n",
    "    data_train.loc[i,'label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv('train_data_formated_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop('ID1_G',axis=1, inplace=True)\n",
    "data_train.drop('ID2_G',axis=1, inplace=True)\n",
    "data_train.drop('ID_T_G',axis=1, inplace=True)\n",
    "data_train.drop('ID_R_G',axis=1, inplace=True)\n",
    "data_train.drop('DATE_G',axis=1, inplace=True)\n",
    "data_train.drop('RESULT_G',axis=1, inplace=True)\n",
    "data_train.drop(['R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'R9', 'R10', 'R11', 'R12',\n",
    "       'R13', 'R14', 'R15', 'R16', 'R17'],axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_train.drop(['label'],1)\n",
    "X = X.fillna(0)\n",
    "Y = data_train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, \n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state = 2,\n",
    "                                                    stratify = Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XgBoost is one the esemble Machine learning models, there is problems in machine learning where learning a single model is not suficent, thus combining multiple ML models is not a bad idea.\n",
    "Briefly esemble methodes consist on combining some machine learning weak models following some a specific architecture (bagging, boosting) to come up with a better model at the end.\n",
    "XgBoost is a boosting model, one of the most used models in Kaggle competition for its powerful capacity to learn and also its scalability to run on multiple computers (team members) also the parallel computing possibility that boosting models offer.\n",
    "During the Boosting learning multiple trees are built sequentially such that a new tree reduce error made by the previous one.\n",
    "let M0 be the first model, it has an error (y - M0(x)), the next model will  learn on (y - M0(x)) and come up with the model M1, and this process goes on ...\n",
    "\n",
    " <img src=\"e7MIgXk.png\" alt=\"Girl in a jacket\" width=\"25%\" > \n",
    "<br>\n",
    "<br>source : https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/\n",
    "<br><strong>Regularization</strong>: XGBoost has an option to penalize complex models through both L1 and L2 regularization. Regularization helps in preventing overfitting\n",
    "<br><strong>Handling sparse data</strong>: Missing values or data processing steps like one-hot encoding make data sparse. XGBoost incorporates a sparsity-aware split finding algorithm to handle different types of sparsity patterns in the data\n",
    "<br><strong>Weighted quantile sketch</strong>: Most existing tree based algorithms can find the split points when the data points are of equal weights (using quantile sketch algorithm). However, they are not equipped to handle weighted data. XGBoost has a distributed weighted quantile sketch algorithm to effectively handle weighted data\n",
    "<br><strong>Block structure for parallel learning</strong>: For faster computing, XGBoost can make use of multiple cores on the CPU. This is possible because of a block structure in its system design. Data is sorted and stored in in-memory units called blocks. Unlike other algorithms, this enables the data layout to be reused by subsequent iterations, instead of computing it again. This feature also serves useful for steps like split finding and column sub-sampling\n",
    "<br><strong>Cache awareness</strong>: In XGBoost, non-continuous memory access is required to get the gradient statistics by row index. Hence, XGBoost has been designed to make optimal use of hardware. This is done by allocating internal buffers in each thread, where the gradient statistics can be stored\n",
    "<br><strong>Out-of-core computing</strong>: This feature optimizes the available disk space and maximizes its usage when handling huge datasets that do not fit into memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source : https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn\n",
    "<br>For the XgBoost model there is lot of parameters to tune and it takes much time to train, thus I will choose some of these parametres that I see are important.\n",
    "<br>\n",
    "<br>\n",
    "<strong>max_depth (int) </strong>– Maximum tree depth for base learners.\n",
    "<br>\n",
    "<strong>learning_rate (float) </strong>– Boosting learning rate (xgb’s “eta”)\n",
    "<br>\n",
    "<strong>n_estimators (int) </strong>– Number of trees to fit.\n",
    "<br>\n",
    "<strong>booster (string) </strong>– Specify which booster to use: gbtree, gblinear or dart.\n",
    "<br>\n",
    "<strong>n_jobs (int) </strong>– Number of parallel threads used to run xgboost. (replaces nthread)\n",
    "<br>\n",
    "<strong>gamma (float) </strong>– Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "<br>\n",
    "<strong>max_delta_step (int) </strong>– Maximum delta step we allow each tree’s weight estimation to be.\n",
    "<br>\n",
    "<strong>subsample (float) </strong>– Subsample ratio of the training instance.\n",
    "<br>\n",
    "<strong>colsample_bytree (float) </strong>– Subsample ratio of columns when constructing each tree.\n",
    "<br>\n",
    "<strong>reg_alpha (float (xgb's alpha)) </strong>– L1 regularization term on weights\n",
    "<br>\n",
    "<strong>reg_lambda (float (xgb's lambda)) </strong>– L2 regularization term on weights\n",
    "<br>\n",
    "<strong>scale_pos_weight (float) </strong>– Balancing of positive and negative weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a classification machine learning model, make use of the simlicty of linear model, LR introduces the sigmoid function to control the output so that the result will take values in {0,1}. Note that for multiple label LR problem multiple binary LR models are learnt as it is the case for sk-learn library. \n",
    " <img src=\"LogReg_1.png\" alt=\"Girl in a jacket\" width=\"35%\" > \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "<br>\n",
    "<br><strong>penalty </strong> : 'l1','l2’, ‘elasticnet’ or ‘none’, optional (default=’l2’)\n",
    "<br><strong>dual</strong> : bool, optional (default=False)\n",
    "<br><strong>tol</strong> : float, optional (default=1e-4)\n",
    "<br><strong>C</strong> : float, optional (default=1.0)\n",
    "<br><strong>fit_intercept</strong> : bool, optional (default=True)\n",
    "<br><strong>max_iter</strong> : int, optional (default=100)\n",
    "<br><strong>multi_class</strong> : str, {‘ovr’, ‘multinomial’, ‘auto’}, optional (default=’ovr’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
      "          tol=0.001, verbose=0, warm_start=False)\n",
      "0.9804360573591343\n",
      "0.979402901612352\n"
     ]
    }
   ],
   "source": [
    "parameters = { 'C' : [0.01,0.1,1,10],\n",
    "               'tol' : [0.001,0.01,0.1],\n",
    "              'solver' : ['lbfgs', 'liblinear']\n",
    "             }  \n",
    "\n",
    "clf_x = LogisticRegression()\n",
    "\n",
    "f1_scorer = make_scorer(f1_score,pos_label=1)\n",
    "\n",
    "grid_obj = GridSearchCV(clf_x,\n",
    "                        scoring=f1_scorer,\n",
    "                        param_grid=parameters,\n",
    "                        cv=5)\n",
    "\n",
    "grid_obj = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "clf_x = grid_obj.best_estimator_\n",
    "print (clf_x)\n",
    "\n",
    "\n",
    "y = clf_x.predict(X_train)\n",
    "print(f1_score(y_train, y, pos_label=1))\n",
    "\n",
    "\n",
    "y = clf_x.predict(X_test)\n",
    "print(f1_score(y_test, y, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a high f1-score with this model, which is a little bit weird to get this value on real data. Let's analyse the coefficient we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.46144315,  4.63390253,  0.96598404, -8.17729698,  3.53709297,\n",
       "        -0.6893501 , -1.76888051]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_x.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is shown the label depends on the first features on the table, such information can not be trustful. I should think of another way to present my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum the values of feature PLi_j in new feature P_i\n",
    "data_train['p_1'] = data_train.apply(lambda x:(x.PL1_2+x.PL1_1+x.PL1_3)/3 ,axis=1)\n",
    "data_train['p_2'] = data_train.apply(lambda x:(x['PL2_1']+x['PL2_2']+x['PL2_3'])/3,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-43659035b10e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'p_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DIFF_pts'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "corr = data_train(['p_1','p_2','DIFF_pts','label']).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PL1_1</th>\n",
       "      <th>PL1_2</th>\n",
       "      <th>PL1_3</th>\n",
       "      <th>PL2_1</th>\n",
       "      <th>PL2_2</th>\n",
       "      <th>PL2_3</th>\n",
       "      <th>DIFF_pts</th>\n",
       "      <th>label</th>\n",
       "      <th>p_1</th>\n",
       "      <th>p_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PL1_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.680801</td>\n",
       "      <td>0.178802</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.030647</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>0.495483</td>\n",
       "      <td>0.902704</td>\n",
       "      <td>0.850293</td>\n",
       "      <td>-0.759420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL1_2</th>\n",
       "      <td>0.680801</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.239083</td>\n",
       "      <td>-0.680801</td>\n",
       "      <td>-0.043323</td>\n",
       "      <td>-0.106583</td>\n",
       "      <td>0.450713</td>\n",
       "      <td>0.749521</td>\n",
       "      <td>0.882579</td>\n",
       "      <td>-0.550651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL1_3</th>\n",
       "      <td>0.178802</td>\n",
       "      <td>0.239083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.178802</td>\n",
       "      <td>-0.132796</td>\n",
       "      <td>0.060550</td>\n",
       "      <td>0.126230</td>\n",
       "      <td>0.198430</td>\n",
       "      <td>0.533158</td>\n",
       "      <td>-0.198165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL2_1</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.680801</td>\n",
       "      <td>-0.178802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030647</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>-0.495483</td>\n",
       "      <td>-0.902704</td>\n",
       "      <td>-0.850293</td>\n",
       "      <td>0.759420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL2_2</th>\n",
       "      <td>-0.030647</td>\n",
       "      <td>-0.043323</td>\n",
       "      <td>-0.132796</td>\n",
       "      <td>0.030647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.211817</td>\n",
       "      <td>-0.148151</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>-0.079648</td>\n",
       "      <td>0.645570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL2_3</th>\n",
       "      <td>-0.000217</td>\n",
       "      <td>-0.106583</td>\n",
       "      <td>0.060550</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.211817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005317</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>-0.032426</td>\n",
       "      <td>0.316656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIFF_pts</th>\n",
       "      <td>0.495483</td>\n",
       "      <td>0.450713</td>\n",
       "      <td>0.126230</td>\n",
       "      <td>-0.495483</td>\n",
       "      <td>-0.148151</td>\n",
       "      <td>-0.005317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447875</td>\n",
       "      <td>0.493002</td>\n",
       "      <td>-0.456532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0.902704</td>\n",
       "      <td>0.749521</td>\n",
       "      <td>0.198430</td>\n",
       "      <td>-0.902704</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.447875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846464</td>\n",
       "      <td>-0.668100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_1</th>\n",
       "      <td>0.850293</td>\n",
       "      <td>0.882579</td>\n",
       "      <td>0.533158</td>\n",
       "      <td>-0.850293</td>\n",
       "      <td>-0.079648</td>\n",
       "      <td>-0.032426</td>\n",
       "      <td>0.493002</td>\n",
       "      <td>0.846464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.683144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_2</th>\n",
       "      <td>-0.759420</td>\n",
       "      <td>-0.550651</td>\n",
       "      <td>-0.198165</td>\n",
       "      <td>0.759420</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.316656</td>\n",
       "      <td>-0.456532</td>\n",
       "      <td>-0.668100</td>\n",
       "      <td>-0.683144</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PL1_1     PL1_2     PL1_3     PL2_1     PL2_2     PL2_3  \\\n",
       "PL1_1     1.000000  0.680801  0.178802 -1.000000 -0.030647 -0.000217   \n",
       "PL1_2     0.680801  1.000000  0.239083 -0.680801 -0.043323 -0.106583   \n",
       "PL1_3     0.178802  0.239083  1.000000 -0.178802 -0.132796  0.060550   \n",
       "PL2_1    -1.000000 -0.680801 -0.178802  1.000000  0.030647  0.000217   \n",
       "PL2_2    -0.030647 -0.043323 -0.132796  0.030647  1.000000  0.211817   \n",
       "PL2_3    -0.000217 -0.106583  0.060550  0.000217  0.211817  1.000000   \n",
       "DIFF_pts  0.495483  0.450713  0.126230 -0.495483 -0.148151 -0.005317   \n",
       "label     0.902704  0.749521  0.198430 -0.902704  0.001944  0.000851   \n",
       "p_1       0.850293  0.882579  0.533158 -0.850293 -0.079648 -0.032426   \n",
       "p_2      -0.759420 -0.550651 -0.198165  0.759420  0.645570  0.316656   \n",
       "\n",
       "          DIFF_pts     label       p_1       p_2  \n",
       "PL1_1     0.495483  0.902704  0.850293 -0.759420  \n",
       "PL1_2     0.450713  0.749521  0.882579 -0.550651  \n",
       "PL1_3     0.126230  0.198430  0.533158 -0.198165  \n",
       "PL2_1    -0.495483 -0.902704 -0.850293  0.759420  \n",
       "PL2_2    -0.148151  0.001944 -0.079648  0.645570  \n",
       "PL2_3    -0.005317  0.000851 -0.032426  0.316656  \n",
       "DIFF_pts  1.000000  0.447875  0.493002 -0.456532  \n",
       "label     0.447875  1.000000  0.846464 -0.668100  \n",
       "p_1       0.493002  0.846464  1.000000 -0.683144  \n",
       "p_2      -0.456532 -0.668100 -0.683144  1.000000  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the label depends on the results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-79142458df6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                         cv=5)\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mgrid_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mclf_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "parameters = { 'learning_rate' : [0.001,0.0001],\n",
    "               'n_estimators' : [100,120,140],\n",
    "               'max_depth': [4,6],\n",
    "               'min_child_weight': [3],\n",
    "               'gamma':[0.4,0.8],\n",
    "               'subsample' : [0.2,0.5,0.8],\n",
    "               'colsample_bytree' : [0.5,0.8],\n",
    "               'scale_pos_weight' : [1],\n",
    "               'reg_alpha':[1e-5]\n",
    "             }  \n",
    "\n",
    "clf = xgb.XGBClassifier()\n",
    "\n",
    "f1_scorer = make_scorer(f1_score,pos_label=1)\n",
    "\n",
    "grid_obj = GridSearchCV(clf,\n",
    "                        scoring=f1_scorer,\n",
    "                        param_grid=parameters,\n",
    "                        cv=5)\n",
    "\n",
    "grid_obj = grid_obj.fit(X_train,y_train)\n",
    "\n",
    "clf_svm = grid_obj.best_estimator_\n",
    "print (clf)\n",
    "\n",
    "\n",
    "y = clf.predict(X_train)\n",
    "print(f1_score(y_train, y, pos_label=1))\n",
    "\n",
    "\n",
    "y = clf.predict(X_test)\n",
    "print(f1_score(y_test, y, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
